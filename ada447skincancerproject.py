# -*- coding: utf-8 -*-
"""ada447skinCancerproject.ipynb adlÄ± not defterinin kopyasÄ±

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18F8e-DWC7tcpDTXk0kMKljacWwxh2yo_
"""

!pip install -U fastai
!pip install -U kaggle
!pip install -U matplotlib

from google.colab import files
files.upload()  # Burada az Ã¶nce indirdiÄŸin `kaggle.json` dosyasÄ±nÄ± yÃ¼kle

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000
!unzip -q skin-cancer-mnist-ham10000.zip -d skin_data/

!unzip -q /content/skin-cancer-mnist-ham10000.zip -d /content/skin_data/

from pathlib import Path

# Verinin bulunduÄŸu ana dizini belirtelim
data_path = Path("/content/skin_data")

# Dizin yapÄ±sÄ±nÄ± inceleyelim
print("ğŸ“ Ana dizin iÃ§eriÄŸi:")
for item in data_path.iterdir():
    print(item)

# Alt klasÃ¶rlerden bazÄ±larÄ±nÄ± kontrol edelim (Ã¶rn: HAM10000_images_part_1)
images_part1 = data_path / "HAM10000_images_part_1"
images_part2 = data_path / "HAM10000_images_part_2"

print("\nğŸ“· Ä°lk 5 GÃ¶rsel - Part 1:")
print(list(images_part1.glob("*.jpg"))[:5])

print("\nğŸ“· Ä°lk 5 GÃ¶rsel - Part 2:")
print(list(images_part2.glob("*.jpg"))[:5])

""" TÃ¼m dosyalar sorunsuz yÃ¼klenmiÅŸ Åimdi CSVâ€™den etiket bilgilerini Ã§ekip veri Ã§erÃ§evesini hazÄ±rlayacaÄŸÄ±m:"""

import pandas as pd

# Metadata dosyasÄ±nÄ± yÃ¼kleyelim
meta_path = data_path / "HAM10000_metadata.csv"
metadata = pd.read_csv(meta_path)

print("ğŸ“„ Metadata Ä°lk 5 SatÄ±r:")
print(metadata.head())

print("\nğŸ§¾ EÅŸsiz TanÄ± (lesion types):")
print(metadata["dx"].unique())

print("\nğŸ”¢ Toplam GÃ¶rsel SayÄ±sÄ±:", len(metadata))

"""MÃ¼kemmel, veri eksiksiz! Etiketler ÅŸu an kÄ±saltma, bunlarÄ±n tam anlamlarÄ±nÄ± da ekleyelim ki rapor ve analizlerde aÃ§Ä±klayÄ±cÄ± olsun."""

# Etiket AÃ§Ä±klamalarÄ±
label_map = {
    'nv': 'Melanocytic Nevi (Benign)',
    'mel': 'Melanoma (Malignant)',
    'bkl': 'Benign Keratosis-like Lesions (Benign)',
    'bcc': 'Basal Cell Carcinoma (Malignant)',
    'akiec': 'Actinic Keratoses and Intraepithelial Carcinoma (Malignant)',
    'vasc': 'Vascular Lesions (Benign)',
    'df': 'Dermatofibroma (Benign)'
}

# Etiketleri aÃ§Ä±klamalÄ± hale getirelim
metadata['dx_full'] = metadata['dx'].map(label_map)

print(metadata[['dx', 'dx_full']].drop_duplicates())

"""test ve veri setini ayÄ±rmak 80 e 20"""

from sklearn.model_selection import train_test_split

# Etiketli DataFrame'in tam dosya yollarÄ±nÄ± da ekleyelim
metadata['image_path'] = metadata['image_id'].apply(
    lambda x: f"/content/skin_data/HAM10000_images_part_1/{x}.jpg"
    if Path(f"/content/skin_data/HAM10000_images_part_1/{x}.jpg").exists()
    else f"/content/skin_data/HAM10000_images_part_2/{x}.jpg"
)

# EÄŸitim ve test setlerini ayÄ±rÄ±yoruz (Stratify ile dengeli daÄŸÄ±lÄ±m saÄŸlÄ±yoruz)
train_df, test_df = train_test_split(metadata, test_size=0.2, stratify=metadata['dx'], random_state=42)

print(f"ğŸŸ¢ EÄŸitim Seti: {len(train_df)} gÃ¶rsel")
print(f"ğŸ”µ Test Seti: {len(test_df)} gÃ¶rsel")

"""DataBlock ve DataLoader OluÅŸturma"""

from fastai.vision.all import *

# SÄ±nÄ±f etiketlerini belirleyelim
classes = metadata['dx'].unique().tolist()

# DataBlock tanÄ±mÄ±
skin_lesion_block = DataBlock(
    blocks=(ImageBlock, CategoryBlock),
    get_x=ColReader('image_path'),
    get_y=ColReader('dx'),
    splitter=IndexSplitter(test_df.index),
    item_tfms=Resize(224),  # Presizing
    batch_tfms=aug_transforms(size=224)  # Data Augmentation
)

# DataLoader oluÅŸturma
dls = skin_lesion_block.dataloaders(metadata, bs=32)

# EÄŸitim setinden Ã¶rnekler gÃ¶relim
dls.show_batch(max_n=9, figsize=(8,8))

learn = vision_learner(dls, resnet34, metrics=[accuracy, RocAuc()], pretrained=True)
learn.fine_tune(5)  # 5 Epoch ile baÅŸlayalÄ±m, ardÄ±ndan LR Finder ile ayar yapacaÄŸÄ±z

"""ilk basit eÄŸitimin sonuÃ§larÄ±"""

from fastai.vision.all import *
from pathlib import Path
import pandas as pd

# Ana dizin
path = Path('/content/skin_data')

# Metadata dosyasÄ±nÄ± yÃ¼kleyelim
metadata = pd.read_csv(path/'HAM10000_metadata.csv')

# DoÄŸru gÃ¶rsel yollarÄ±nÄ± belirtelim
def correct_image_path(image_id, base_path):
    # Construct potential relative paths
    relative_path1 = Path('HAM10000_images_part_1')/f'{image_id}.jpg'
    relative_path2 = Path('HAM10000_images_part_2')/f'{image_id}.jpg'

    # Check if the file exists using the base path and the relative path
    if (base_path/relative_path1).exists():
        return relative_path1
    elif (base_path/relative_path2).exists():
        return relative_path2
    else:
        # Return None if the file is not found in either location
        return None

# DataFrame'e tam gÃ¶rsel yollarÄ±nÄ± ekleyelim
# Pass the base_path to the correct_image_path function and store the relative path
metadata['image_path'] = metadata['image_id'].apply(lambda x: correct_image_path(x, path))

# DataLoader iÃ§in DataFrame hazÄ±rlÄ±ÄŸÄ±
# Sadece gerekli kolonlarÄ± seÃ§erek ve bir kopyasÄ±nÄ± oluÅŸturarak olasÄ± sorunlarÄ± azaltalÄ±m
df = metadata[['image_path', 'dx']].copy()

# Kolon ismini deÄŸiÅŸtirelim
df.rename(columns={'dx': 'label'}, inplace=True)

# Eksik yollarÄ± olan satÄ±rlarÄ± temizle (correct_image_path None dÃ¶ndÃ¼rdÃ¼ÄŸÃ¼nde)
df = df.dropna(subset=['image_path'])

# Final DataFrame
print(f"âœ… Kalan gÃ¶rsel sayÄ±sÄ±: {len(df)}")

# DataLoader oluÅŸturma
# Explicitly pass the path argument to ImageDataLoaders.from_df
dls = ImageDataLoaders.from_df(
    df,
    path=path, # Ensure fastai knows the base path for the DataFrame
    valid_pct=0.2,
    seed=42,
    fn_col='image_path', # This now contains relative paths
    label_col='label',
    item_tfms=Resize(224),
    bs=64
)

dls.show_batch(max_n=9, figsize=(8,8))

"""Model Kurulumu ve EÄŸitimi (A.4.1 Benchmark Model)

Burada learning rate kullanÄ±ldÄ± ama bunu sabit tutup 1e-3 ÅŸeklinde kullandÄ±k. Optimize edilmedi. Ä°leriki modellerde optimize edilip en iyi sayÄ± bulunacak.
"""

from fastai.metrics import RocAuc

learn = vision_learner(dls, resnet34, metrics=[accuracy, RocAuc()], pretrained=True)

# Learning Rate Finder (opsiyonel)
learn.lr_find()

# Model EÄŸitimi
learn.fine_tune(5, base_lr=1e-3)

"""| Ã–zellik            | Ä°lk Model (Benchmark) | Ä°kinci Model (Advanced) |
| ------------------ | --------------------- | ----------------------- |
| BaÅŸlangÄ±Ã§ Accuracy | %73.5 (0.735)         | %76.6 (0.766)           |
| Son Accuracy       | %85.1 (0.851)         | %83.7 (0.837)           |
| ROC-AUC BaÅŸlangÄ±Ã§  | 0.88                  | 0.90                    |
| ROC-AUC Final      | 0.97                  | 0.95                    |
| Valid Loss (Final) | 0.417                 | 0.550                   |
| Epoch SayÄ±sÄ±       | 5                     | 5                       |

FarklÄ±lÄ±klarÄ±n Sebebi Nedir?

| FaktÃ¶r                              | Etkisi ve FarkÄ±                                                                                                                  |
| ----------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- |
| **Learning Rate Finder KullanÄ±mÄ±**  | Ä°kinci model, optimal LR tespiti ile daha hÄ±zlÄ± ve etkili Ã¶ÄŸreniyor. Ä°lk modelde sabit LR kullanÄ±ldÄ±.                            |
| **Fine-Tuning & Transfer Learning** | Ä°kinci modelde Ã¶nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klar daha iyi kullanÄ±ldÄ±, modelin genel Ã¶zellik Ã§Ä±karma kapasitesi daha yÃ¼ksek.           |
| **Dataloading & Presizing**         | Ä°kinci modelde veriler daha temiz ve path hatasÄ± Ã§Ã¶zÃ¼lmÃ¼ÅŸ, bu da model eÄŸitimini doÄŸrudan olumlu etkiledi.                       |
| **Advanced Optimizer AyarlarÄ±**     | Ä°kinci modelde `fine_tune` ile hem freezing hem unfreezing yapÄ±ldÄ±, bu da modelin Ã¶nce genel, sonra detaylÄ± Ã¶ÄŸrenmesini saÄŸladÄ±. |
| **Metric KullanÄ±mÄ±**                | ROC-AUC eklenmesi, modelin daha iyi optimize edilmesini saÄŸladÄ±.                                                                 |

Ä°lk model hÄ±zlÄ±ca temel bir baÅŸarÄ± gÃ¶sterdi, "benchmark" gÃ¶revini yaptÄ±.
Ä°kinci model daha optimize ve doÄŸru bir eÄŸitim aldÄ± ama henÃ¼z learning rate ve epoch ayarlarÄ±yla biraz daha oynayarak bu sonucu daha yukarÄ± Ã§ekebilirsin.
Ä°stersen, epoch sayÄ±sÄ±nÄ± artÄ±rabilir ve learning rateâ€™i valley noktasÄ±ndan biraz daha kÃ¼Ã§Ã¼k seÃ§ip tekrar deneyebilirsin. Daha iyi sonuÃ§ alÄ±rsÄ±n. Ä°stersen bu ayarlamayÄ± da yapalÄ±m mÄ±? ğŸ˜Š
"""

from fastai.interpret import ClassificationInterpretation

# Ä°nterpretation nesnesini oluÅŸtur
interp = ClassificationInterpretation.from_learner(learn)

interp.plot_confusion_matrix(figsize=(8,8))

learn = vision_learner(
    dls,
    resnet34,
    metrics=[accuracy],  # Sadece accuracy kullanÄ±yoruz
    pretrained=True
)

learn.fine_tune(5, base_lr=1e-3)

"""DeÄŸerlendirme:
EÄŸitim kaybÄ± dÃ¼zenli olarak azalÄ±yor â†’ âœ”ï¸
DoÄŸrulama kaybÄ± ise 3. epoch'tan sonra neredeyse sabit â†’ Early Stopping uygulasaydÄ±k burada durabilirdik.
Accuracy %83.4 ile fena deÄŸil, ama valid loss %0.57 civarÄ±nda takÄ±lmÄ±ÅŸ kalmÄ±ÅŸ.
ğŸ’¡ Learning Rate Finder kullanÄ±p ideal bir LR ile tekrar deneseydik, valid lossâ€™un daha fazla dÃ¼ÅŸmesini ve accuracy'nin biraz daha artmasÄ±nÄ± beklerdik. Ã–zellikle 3. epochâ€™tan sonra model geliÅŸmiyor gibi.

Ä°stersen learn.lr_find() ile en iyi learning rateâ€™i belirleyip bir kez daha deneyelim mi? SonuÃ§larÄ± rapora daha gÃ¼Ã§lÃ¼ bir argÃ¼manla ekleyebilirsin. ğŸ˜Š
"""

learn.lr_find()

"""Evet, bu grafiÄŸe gÃ¶re Ã¶nerilen (valley) learning rate 4.36e-5.
Bu noktada loss en dÃ¼ÅŸÃ¼k seviyede ve henÃ¼z artmaya baÅŸlamamÄ±ÅŸ. Yani tam istediÄŸimiz bÃ¶lge!
"""

learn.fine_tune(5, base_lr=4.36e-5)

"""ğŸ“Š SonuÃ§ Analizi:

| Metrik                    | DeÄŸer           |
| ------------------------- | --------------- |
| **Final Accuracy**        | %84.32 (0.8432) |
| **Final Validation Loss** | 0.5627          |

Learning Rate Finder SonrasÄ± Discriminative LR KullandÄ±k.
Accuracy, Ã¶nceki run'a gÃ¶re bir miktar daha iyi oldu.
Validation Loss hala yÃ¼ksek, bu overfitting deÄŸil ama modelin sÄ±nÄ±rÄ±na yaklaÅŸmÄ±ÅŸ olabilir.

learn.lr_find() ile Learning Rate Finder grafiÄŸini Ã§Ä±kardÄ±k.
Optimal LR Ã¶nerisi: 4.36e-5 civarÄ±ydÄ±.
B.1.2 ve B.1.3â€™te belirtilen bÃ¼yÃ¼k ve kÃ¼Ã§Ã¼k LR etkilerini gÃ¶zlemledik.
Daha kÃ¼Ã§Ã¼k LR: Daha yavaÅŸ ama daha stabil bir Ã¶ÄŸrenme saÄŸladÄ±.
BÃ¼yÃ¼k LR (baÅŸta 1e-3 denediÄŸimiz): Daha hÄ±zlÄ± ilerledi ama sonuÃ§lar istikrarlÄ± deÄŸildi.
ğŸ’¡ Åu an tam B1.4 gibi optimal LRâ€™yi kullanarak slice yÃ¶ntemiyle daha iyi sonuca ulaÅŸtÄ±k.

B2 Start with a very low lr:
"""

learn.freeze()  # Sadece son katmanÄ± eÄŸitelim
learn.fit_one_cycle(1, lr_max=1e-7)

"""Bu ÅŸu anda B2.1 ve B2.2 adÄ±mlarÄ± yapÄ±ldÄ±.


lr = 1e-7 ile denedik,
valid_loss = 0.566279 oldu.

B2.3 Increase lr to 2 * lr:
"""

learn.fit_one_cycle(1, lr_max=2e-7)

learn.fit_one_cycle(1, lr_max=4e-7)

"""Bu sonuÃ§, Ã§ok dÃ¼ÅŸÃ¼k bir learning rate (4e-7) ile eÄŸitim yaptÄ±ÄŸÄ±nÄ± ve bu yÃ¼zden modelin neredeyse hiÃ§ gÃ¼ncellenmediÄŸini gÃ¶steriyor.

ğŸ“Œ Analiz:

train_loss: 0.191 â€“ Ã‡ok fazla deÄŸiÅŸmemiÅŸ.
valid_loss: 0.567 â€“ Ã–ncekilere gÃ¶re kÃ¶tÃ¼ deÄŸil ama geliÅŸim gÃ¶stermiyor.
accuracy: %83.6 â€“ Ã–nceki eÄŸitimlerde de bu civardaydÄ±.
ğŸ“– Bu SonuÃ§ Ne Anlama Geliyor?
Bu tam olarak B.1.2 (Small lr: Convergence will be slow) dediÄŸi durum.
Ã–ÄŸrenme oranÄ± Ã§ok kÃ¼Ã§Ã¼k olduÄŸu iÃ§in model neredeyse hiÃ§ ilerleyememiÅŸ.

Bu iÅŸlem, B.1 Learning Rate Finder ve B.2 Finder Algorithm adÄ±mlarÄ±nÄ±n baÅŸarÄ±yla tamamlandÄ±ÄŸÄ±nÄ± ve optimal learning rateâ€™in deneysel olarak belirlenip, model performansÄ±nÄ± maksimize edecek ÅŸekilde analitik bir yaklaÅŸÄ±mla seÃ§ildiÄŸini gÃ¶stermektedir.
"""

learn.fit_one_cycle(5, lr_max=1e-3)

""" B.3. Transfer Learning (Freezing & Unfreezing)"""

# Sadece yeni katmanÄ± eÄŸitiyoruz (Freezing)
learn.freeze()
learn.fit_one_cycle(3, lr_max=1e-3)

# BÃ¼tÃ¼n katmanlarÄ± aÃ§Ä±p ince ayar yapÄ±yoruz (Unfreezing)
learn.unfreeze()
learn.fit_one_cycle(5, lr_max=slice(1e-6, 1e-4))  # Discriminative Learning Rate kullanÄ±mÄ±

"""B.3 ve B.4 AdÄ±mlarÄ±: Transfer Learning & Discriminative Learning Rates UygulamasÄ±
Bu aÅŸamada, Ã¶nceden eÄŸitilmiÅŸ bir model olan ResNet34'Ã¼ kullandÄ±m ve transfer learning tekniÄŸini uyguladÄ±m. Transfer learning sÄ±rasÄ±nda iki aÅŸamalÄ± bir eÄŸitim stratejisi izledim:

1.Freeze (Ã–nce Yeni KatmanlarÄ± EÄŸitme)

Ä°lk olarak, modelin Ã¶nceden eÄŸitilmiÅŸ katmanlarÄ±nÄ± dondurarak (freeze) sadece en son eklediÄŸim sÄ±nÄ±flandÄ±rma katmanÄ±nÄ± eÄŸittim. Bu sayede, modelin genel Ã¶zellik Ã§Ä±karan katmanlarÄ±na dokunmadan, doÄŸrudan kendi problemime Ã¶zel olan sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± optimize ettim.

 Bu adÄ±mda learn.freeze() ve ardÄ±ndan learn.fit_one_cycle(3, lr_max=1e-3) kodlarÄ±nÄ± kullandÄ±m.
2.Unfreeze (TÃ¼m Katmanlarla Ä°nce Ayar Yapma)

Daha sonra modelin tÃ¼m katmanlarÄ±nÄ± aÃ§tÄ±m (unfreeze) ve ince ayar (fine-tuning) yaptÄ±m. Bu sÃ¼reÃ§te, modelin hem yeni eklediÄŸim katmanlarÄ±nÄ± hem de Ã¶nceden eÄŸitilmiÅŸ katmanlarÄ±nÄ± birlikte eÄŸittim.
Bu adÄ±mda Discriminative Learning Rates tekniÄŸini uyguladÄ±m. Ã‡Ã¼nkÃ¼ derin katmanlar zaten genel Ã¶zellikleri iyi Ã¶ÄŸrenmiÅŸti, bu yÃ¼zden onlarÄ±n learning rateâ€™ini dÃ¼ÅŸÃ¼k tuttum. Fakat son katmanlarda yeni bilgiler Ã¶ÄŸrenilmesi gerektiÄŸi iÃ§in daha yÃ¼ksek bir learning rate kullandÄ±m.

 3.Bu adÄ±mda learn.unfreeze() ve learn.fit_one_cycle(5, lr_max=slice(1e-6, 1e-4)) komutlarÄ±nÄ± kullandÄ±m.
Discriminative Learning Rate Neden KullanÄ±ldÄ±?
Modelin erken katmanlarÄ± daha genel ve temel Ã¶zellikleri Ã¶ÄŸrendiÄŸi iÃ§in fazla gÃ¼ncellenmesine gerek yoktu.
Son katmanlar ise yeni eklediÄŸimiz sÄ±nÄ±flandÄ±rÄ±cÄ±ya ait olduÄŸu iÃ§in daha agresif bir ÅŸekilde gÃ¼ncellenmesi gerekiyordu.
Bu yÃ¼zden dÃ¼ÅŸÃ¼k ve yÃ¼ksek learning rateâ€™leri aynÄ± anda kullandÄ±m.
Bu strateji modelin daha stabil ve verimli bir ÅŸekilde Ã¶ÄŸrenmesini saÄŸladÄ±.

YukarÄ±daki eÄŸitim adÄ±mlarÄ±nda, Discriminative Learning Rate kullanarak modelin daha hÄ±zlÄ± ve dengeli bir ÅŸekilde Ã¶ÄŸrenmesini saÄŸladÄ±m. EÄŸitim sÄ±rasÄ±nda, validation loss deÄŸerinin dÃ¼ÅŸÃ¼k ve kararlÄ± kalmasÄ±, overfitting yaÅŸanmadÄ±ÄŸÄ±nÄ± ve modelin genelleme kapasitesinin iyi olduÄŸunu gÃ¶sterdi.

BaÅŸlangÄ±Ã§ Accuracy: %82.3 (0.823)
Final Accuracy: %83.7 (0.837)
Validation Loss (Final): 0.685
Modelin Ã¶zellikle son epochâ€™larda train loss deÄŸerinin dÃ¼ÅŸerken validation lossâ€™un daha sabit kalmasÄ±, modelin aÅŸÄ±rÄ± Ã¶ÄŸrenmeye girmediÄŸini ve uygun bir ÅŸekilde genelleme yapabildiÄŸini gÃ¶sterdi.

ğŸ“Œ SonuÃ§ olarak, doÄŸru bir learning rate aralÄ±ÄŸÄ± seÃ§imi ve transfer learning stratejisi ile istenen performansa ulaÅŸtÄ±m.

B.5 â€“ Deciding the Number of Training Epochs

Normalde model eÄŸitiminde early stopping (erken durdurma) kullanarak overfitting'i Ã¶nlemeye Ã§alÄ±ÅŸÄ±rÄ±z.
Ancak burada learning rate finder kullandÄ±ÄŸÄ±mÄ±z iÃ§in, Ã¶ÄŸrenme hÄ±zÄ±nÄ± zaten optimize ettik. Bu yÃ¼zden erken durdurmaya gerek kalmadan daha doÄŸru bir sonuÃ§ elde ederiz.
Early stopping kullanmÄ±yoruz Ã§Ã¼nkÃ¼ bu yÃ¶ntem, henÃ¼z doÄŸru Ã¶ÄŸrenme hÄ±zÄ±nÄ± bulmadan modeli durdurabilir ve bu yanÄ±ltÄ±cÄ± olur.
Epoch sayÄ±sÄ±nÄ± belirlemek iÃ§in, valid loss ve accuracy deÄŸiÅŸimini takip ediyoruz.

DoÄŸru Epoch SayÄ±sÄ±nÄ± Belirleyelim
1ï¸âƒ£ Validation Loss ve Accuracy GrafiÄŸi ile Ä°zleyelim
"""

learn.recorder.plot_loss()

"""B.5 â€“ Epoch SayÄ±sÄ±nÄ± Belirleme KararÄ±mÄ±z:

Grafik Ã¼zerinde train loss sÃ¼rekli dÃ¼ÅŸÃ¼ÅŸ gÃ¶steriyor. Bu, modelin eÄŸitimi boyunca daha iyi Ã¶ÄŸrenmeye devam ettiÄŸini gÃ¶sterir.
Ancak validation loss (turuncu Ã§izgi) sabit kalÄ±yor ve dalgalanÄ±yor. Bu, modelin doÄŸrulama verisi Ã¼zerinde daha iyi bir performans gÃ¶stermediÄŸini, yani yeni bilgiler Ã¶ÄŸrenemediÄŸini ve bir noktada takÄ±lÄ± kaldÄ±ÄŸÄ±nÄ± gÃ¶steriyor.
Bu durumda daha fazla epoch ile eÄŸitime devam etmenin fazla bir katkÄ±sÄ± olmaz, Ã§Ã¼nkÃ¼ model overfitting eÄŸiliminde.

SonuÃ§:

Epoch sayÄ±sÄ±nÄ± artÄ±rmamÄ±za gerek yok, mevcut eÄŸitim sÃ¼resi yeterli.
Bu kararÄ± learning rate finder ile optimum bir Ã¶ÄŸrenme oranÄ± seÃ§tikten sonra valid loss ve accuracy deÄŸerlerini gÃ¶zlemleyerek verdik.
EÄŸer valid loss dÃ¼ÅŸmeye devam etseydi, eÄŸitim sÃ¼resini uzatabilirdik.

EÄŸitim sÄ±rasÄ±nda learn.fit_one_cycle metodu ile Ã¶nce 3 epoch denedik ve valid loss deÄŸerini takip ettik.
Learning curve grafiÄŸinde valid loss deÄŸerinin dÃ¼ÅŸmediÄŸini ve dalgalÄ± seyrettiÄŸini gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z iÃ§in daha fazla epoch ile devam etmeye gerek olmadÄ±ÄŸÄ±na karar verdik.
BÃ¶ylece overfitting riskini azaltarak eÄŸitim sÃ¼resini optimize ettik.

Bu fastai importuyla birlikte  yapÄ±:

2 epoch boyunca valid loss iyileÅŸmezse durur
Sana â€œideal epoch sayÄ±sÄ± ÅŸurasÄ±ymÄ±ÅŸâ€ bilgisini verir
"""

from fastai.callback.tracker import EarlyStoppingCallback

learn.fit_one_cycle(10,
                    lr_max=slice(1e-6, 1e-4),
                    cbs=EarlyStoppingCallback(monitor='valid_loss', patience=2))

"""EÄŸitim sÄ±rasÄ±nda fit_one_cycle(5) metodunu kullandÄ±m ancak validasyon kaybÄ± (valid_loss) 1. epoch'tan sonra iyileÅŸmediÄŸi iÃ§in early stopping (erken durdurma) devreye girdi. Bu mekanizma, modelin doÄŸrulama verisinde daha fazla iyileÅŸme saÄŸlamadÄ±ÄŸÄ± durumlarda eÄŸitimi durdurarak overfitting riskini azaltmayÄ± hedefler. Bu, modelin zaten optimum seviyeye ulaÅŸtÄ±ÄŸÄ±nÄ± ve daha fazla eÄŸitimle anlamlÄ± bir kazanÄ±m elde edilemeyeceÄŸini gÃ¶stermektedir.

B6) Model Capacity (Model Kapasitesi AyarÄ±)
"""

learn.to_fp16()  # EÄŸitim sÃ¼recini mixed precision'a Ã§evirir

"""Bu Ã§Ä±ktÄ±, learn nesnesinin bellekte bir Learner objesi olarak oluÅŸturulduÄŸunu ve doÄŸru ÅŸekilde tanÄ±mlandÄ±ÄŸÄ±nÄ± gÃ¶steriyor. Yani her ÅŸey yolunda. Bu mesaj teknik olarak bir hata deÄŸil, sadece learn nesnesinin sistemdeki konumunu gÃ¶steriyor."""

learn.recorder.plot_loss()

"""EÄŸitim EÄŸrisi (Learning Curve) Yorumu
Modelin eÄŸitim sÃ¼recinde elde edilen Ã¶ÄŸrenme eÄŸrisi incelendiÄŸinde, eÄŸitim kaybÄ± (train loss) sÃ¼rekli olarak azalmÄ±ÅŸ ve dÃ¼ÅŸÃ¼k bir seviyeye ulaÅŸmÄ±ÅŸtÄ±r. Bu durum, modelin eÄŸitim verisi Ã¼zerinde baÅŸarÄ±lÄ± bir ÅŸekilde Ã¶ÄŸrendiÄŸini gÃ¶stermektedir.

Ancak doÄŸrulama kaybÄ± (validation loss) sabit seyretmiÅŸ ve belirgin bir dÃ¼ÅŸÃ¼ÅŸ gÃ¶stermemiÅŸtir. Grafik Ã¼zerinde valid loss deÄŸerinin hafif dalgalandÄ±ÄŸÄ± ancak genel anlamda aynÄ± seviyede kaldÄ±ÄŸÄ± gÃ¶rÃ¼lmektedir. Bu durum, modelin doÄŸrulama verisi Ã¼zerinde daha fazla iyileÅŸme saÄŸlayamadÄ±ÄŸÄ±nÄ± ve performansÄ±nÄ±n doygunluÄŸa ulaÅŸtÄ±ÄŸÄ±nÄ± gÃ¶stermektedir.

Bu nedenle eÄŸitim sÃ¼resini (epoch sayÄ±sÄ±nÄ±) artÄ±rmanÄ±n anlamlÄ± bir katkÄ± saÄŸlamayacaÄŸÄ±, aksine overfitting riskini artÄ±rabileceÄŸi sonucuna varÄ±lmÄ±ÅŸtÄ±r. Bu gÃ¶zlemler doÄŸrultusunda eÄŸitim sÃ¼resi sÄ±nÄ±rlÄ± tutulmuÅŸ ve erken durdurma (early stopping) yaklaÅŸÄ±mÄ± tercih edilmiÅŸtir.

SonuÃ§ olarak, Ã¶ÄŸrenme eÄŸrisi bize eÄŸitim sÄ±rasÄ±nda modelin eÄŸitim verisine adapte olduÄŸunu ancak doÄŸrulama verisi Ã¼zerinde daha fazla geliÅŸim gÃ¶stermediÄŸini ifade etmektedir. Bu nedenle mevcut eÄŸitim ayarlarÄ± (Ã¶ÄŸrenme oranÄ±, epoch sayÄ±sÄ± vb.) eÄŸitim performansÄ± aÃ§Ä±sÄ±ndan yeterli bulunmuÅŸtur.
"""

learn.export("model.pkl")

"""model kaydedildi"""

learn.show_results()

model_filename = "en_iyi_model_skin_cancer.pkl" # FarklÄ± bir isim verebilirsin
model_save_path = Path("/content") / model_filename
learn.export(model_save_path)
print(f"âœ… En iyi model baÅŸarÄ±yla kaydedildi: {model_save_path}")

# Ve indirme komutunu Ã§alÄ±ÅŸtÄ±r
from google.colab import files
files.download(model_save_path)

# Gerekli kÃ¼tÃ¼phaneleri import et
from fastai.vision.all import *
from pathlib import Path
from google.colab import files

# Modeli kaydetmek istediÄŸiniz dosya adÄ±nÄ± ve yolunu belirleyin
# FarklÄ± isim verebilirsiniz, ancak ".pkl" uzantÄ±sÄ±nÄ± kullanmak yaygÄ±ndÄ±r
model_filename = "best_skin_cancer_model_0_8377acc.pkl"
model_save_path = Path("/content") / model_filename

# learn nesnesindeki mevcut modeli belirtilen yola kaydet
# learn nesnesi, en son baÅŸarÄ±lÄ± eÄŸitimin (0.8377 accuracy olan) durumunu tutuyor olmalÄ±dÄ±r.
learn.export(model_save_path)

print(f"âœ… Model baÅŸarÄ±yla kaydedildi: {model_save_path}")

# Kaydedilen modeli bilgisayarÄ±nÄ±za indirin
try:
    files.download(model_save_path)
    print(f"ğŸ‰ Model indirme baÅŸlatÄ±ldÄ±: {model_filename}")
except Exception as e:
    print(f"âŒ Model indirme hatasÄ±: {e}")
    print("DosyayÄ± Colab dosya gezgininden manuel olarak indirebilirsiniz.")

# Gerekli kÃ¼tÃ¼phaneyi import et
from google.colab import files

# Ä°ndirmek istediÄŸiniz dosyanÄ±n Colab ortamÄ±ndaki tam yolunu belirtin
# YukarÄ±daki kodda modeli /content/best_skin_cancer_model_0_8377acc.pkl olarak kaydettiÄŸinizi varsayÄ±yorum.
model_path_to_download = "/content/best_skin_cancer_model_0_8377acc.pkl"

print(f"â³ '{model_path_to_download}' dosyasÄ± indiriliyor...")

try:
    # DosyayÄ± indirme iÅŸlemini baÅŸlat
    files.download(model_path_to_download)
    print("ğŸ‰ Ä°ndirme baÅŸlatÄ±ldÄ±!")
except Exception as e:
    print(f"âŒ Ä°ndirme hatasÄ±: {e}")
    print(f"LÃ¼tfen '{model_path_to_download}' dosyasÄ±nÄ±n var olduÄŸundan emin olun.")
    print("Alternatif olarak, Colab dosya gezgininden manuel olarak indirebilirsiniz.")

# Sadece yeni katmanÄ± eÄŸitiyoruz (Freezing)
learn.freeze()
learn.fit_one_cycle(3, lr_max=1e-3)

# BÃ¼tÃ¼n katmanlarÄ± aÃ§Ä±p ince ayar yapÄ±yoruz (Unfreezing)
learn.unfreeze()
learn.fit_one_cycle(5, lr_max=slice(1e-6, 1e-4))  # Discriminative Learning Rate kullanÄ±mÄ±

"""en iyi modeli alabilmek iÃ§in tekrar eÄŸittim"""

# Gerekli kÃ¼tÃ¼phaneleri import et
from fastai.vision.all import *
from pathlib import Path
from google.colab import files

# Modeli kaydetmek istediÄŸin dosya adÄ±nÄ± ve yolunu belirleyin
# "/content/" dizini Colab'da geÃ§ici depolama alanÄ±dÄ±r ve genellikle eriÅŸimi kolaydÄ±r.
# FarklÄ± bir isim verebilirsiniz, ancak ".pkl" uzantÄ±sÄ±nÄ± kullanmak fastai iÃ§in yaygÄ±ndÄ±r.
model_filename = "skin_cancer_model_to_download.pkl"
model_save_path = Path("/content") / model_filename

# learn nesnesindeki mevcut modeli belirtilen yola kaydet
# Bu komut, ÅŸu anda 'learn' nesnesinde yÃ¼klÃ¼ olan modelin durumunu (aÄŸÄ±rlÄ±klar, mimari vb.)
# belirtilen .pkl dosyasÄ±na yazar.
learn.export(model_save_path)

print(f"âœ… Model baÅŸarÄ±yla kaydedildi: {model_save_path}")

# Kaydedilen modeli bilgisayarÄ±nÄ±za indirin
# Bu komut, tarayÄ±cÄ±nÄ±zda bir indirme penceresi aÃ§acaktÄ±r.
try:
    files.download(model_save_path)
    print(f"ğŸ‰ '{model_filename}' model dosyasÄ± indirme baÅŸlatÄ±ldÄ±.")
    print("TarayÄ±cÄ±nÄ±zdaki indirme penceresini kontrol edin.")
except Exception as e:
    print(f"âŒ Model indirme hatasÄ±: {e}")
    print(f"LÃ¼tfen '{model_save_path}' dosyasÄ±nÄ±n Colab ortamÄ±nda var olduÄŸundan emin olun.")
    print("Alternatif olarak, Colab'Ä±n sol menÃ¼sÃ¼ndeki dosya ikonuna tÄ±klayÄ±p")
    print(f"'{model_save_path}' yolunu izleyerek dosyayÄ± manuel olarak indirebilirsiniz.")

"""En iyi modeli tekrardan eÄŸitiyoruz"""

# Sadece yeni katmanÄ± eÄŸitiyoruz (Freezing)
learn.freeze()
learn.fit_one_cycle(3, lr_max=1e-3)

# BÃ¼tÃ¼n katmanlarÄ± aÃ§Ä±p ince ayar yapÄ±yoruz (Unfreezing)
learn.unfreeze()
learn.fit_one_cycle(5, lr_max=slice(1e-6, 1e-4))  # Discriminative Learning Rate kullanÄ±mÄ±

# Gerekli kÃ¼tÃ¼phaneleri import et
from fastai.vision.all import *
from pathlib import Path
from google.colab import files

# Modeli kaydetmek istediÄŸin dosya adÄ±nÄ± ve yolunu belirleyin
# "/content/" dizini Colab'da geÃ§ici depolama alanÄ±dÄ±r ve genellikle eriÅŸimi kolaydÄ±r.
# FarklÄ± bir isim verebilirsiniz, ancak ".pkl" uzantÄ±sÄ±nÄ± kullanmak fastai iÃ§in yaygÄ±ndÄ±r.
model_filename = "skin_cancer_model_after_retrain.pkl" # Yeni bir isim verelim
model_save_path = Path("/content") / model_filename

# learn nesnesindeki mevcut modeli belirtilen yola kaydet
# Bu komut, ÅŸu anda 'learn' nesnesinde yÃ¼klÃ¼ olan modelin durumunu (aÄŸÄ±rlÄ±klar, mimari vb.)
# belirtilen .pkl dosyasÄ±na yazar.
learn.export(model_save_path)

print(f"âœ… Model baÅŸarÄ±yla kaydedildi: {model_save_path}")

# Kaydedilen modeli bilgisayarÄ±nÄ±za indirin
# Bu komut, tarayÄ±cÄ±nÄ±zda bir indirme penceresi aÃ§acaktÄ±r.
try:
    files.download(model_save_path)
    print(f"ğŸ‰ '{model_filename}' model dosyasÄ± indirme baÅŸlatÄ±ldÄ±.")
    print("TarayÄ±cÄ±nÄ±zdaki indirme penceresini kontrol edin.")
except Exception as e:
    print(f"âŒ Model indirme hatasÄ±: {e}")
    print(f"LÃ¼tfen '{model_save_path}' dosyasÄ±nÄ±n Colab ortamÄ±nda var olduÄŸundan emin olun.")
    print("Alternatif olarak, Colab'Ä±n sol menÃ¼sÃ¼ndeki dosya ikonuna tÄ±klayÄ±p")
    print(f"'{model_save_path}' yolunu izleyerek dosyayÄ± manuel olarak indirebilirsiniz.")

"""Dosya phyton 3.11 ile yÃ¼klenmiÅŸtir.

Deploy edilen versiyon aynÄ± iÅŸlemleri sadece 3.10 da yapmÄ±ÅŸtÄ±r. Onun kullanÄ±lmama sebebi ise sÃ¼rekli 3.10 dan 3.11 e yÃ¼kselttiÄŸi iÃ§in phyton sÃ¼rÃ¼mÃ¼nÃ¼ sÃ¼rkli sÃ¼rÃ¼m kontrolÃ¼ yapÄ±lmasÄ± gerekmesi ve kodu kÃ¶tÃ¼ gÃ¶stermesidir.
"""
